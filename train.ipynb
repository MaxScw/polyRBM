{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97609a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import polyRBM\n",
    "import analysisUtility as anaU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533dada",
   "metadata": {},
   "source": [
    "## Training routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4441bcc",
   "metadata": {},
   "source": [
    "### ring chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a598c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainLengths = [8, 32]\n",
    "networkSizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500]\n",
    "parent = os.getcwd()\n",
    "savepath = ###directory to save training results in###\n",
    "fname_8 = ###file path of N=8 simulation data###\n",
    "fname_32 = ###file path of N=32 simulation data###\n",
    "fnames = [fname_8, fname_32]\n",
    "\n",
    "for ind, l in enumerate(chainLengths):\n",
    "    fname = fnames[ind]\n",
    "    dataset = polyRBM.CubicChainDataset(fname, 2)\n",
    "    div = int(0.7*len(dataset.data))\n",
    "    ringbonds = np.zeros((len(dataset.bonds[:, 0, 0]), len(dataset.bonds[0, :, 0])+1, len(dataset.bonds[0, 0, :])))\n",
    "    ringbonds[:, :-1, :] = dataset.bonds\n",
    "    ringbonds[:, -1, :] = -np.cumsum(dataset.bonds, axis=1)[:, -1, :]\n",
    "    dataset.bonds = ringbonds\n",
    "    dataset.bits = polyRBM.bondsToBits2DYu(dataset.bonds)\n",
    "    dataset.data = torch.from_numpy(dataset.bits).float()\n",
    "\n",
    "    testset = dataset.bits[div:int(len(dataset.data))]\n",
    "    dataset.bits = dataset.bits[:div]\n",
    "    dataset.bonds = dataset.bonds[:div]\n",
    "    dataset.data = dataset.data[:div]\n",
    "    \n",
    "    for n in networkSizes:\n",
    "        run = f'rw_exclVol_rings_N{l}_h{int(n)}' #unique identifier is automatically created\n",
    "        os.mkdir(parent+'/'+savepath+f'repr_results[model={run}]')\n",
    "        batchsize = 10\n",
    "        n_vis = 2*(l+1-2)\n",
    "        n_hidden = int(n)\n",
    "        k = 2\n",
    "        rbm_lr = 10**-2\n",
    "        rbm_epochs= 1\n",
    "        rbm_verbose = False\n",
    "        \n",
    "        train_loader = polyRBM.DataLoader(dataset, batch_size=batchsize, shuffle=True) \n",
    "        rbm = polyRBM.RBM(n_vis=n_vis, n_hin=n_hidden, k=k, oneHot=False, chainlength=l)\n",
    "        \n",
    "        print(f\"START training of RBM [N={l}, n_hidden={int(n)}]\")\n",
    "        print(os.getcwd())\n",
    "        loss, recon_error, countList = polyRBM.train_RBM(rbm=rbm, train_loader=train_loader, epochs=rbm_epochs, \n",
    "                                                 lr=rbm_lr, verbose=rbm_verbose, ninputs=n_vis, \n",
    "                                                 save_model=True, save_path=savepath+f'{run}_rbm', \n",
    "                                                 testset=torch.from_numpy(testset).float(), momentum=0.5, calc_loops=True)\n",
    "        np.save(savepath+f'repr_results[model={run}]/{run}_loss.npy', loss)\n",
    "        np.save(savepath+f'repr_results[model={run}]/{run}_loops.npy', countList)\n",
    "        all_samples = []\n",
    "        \n",
    "        for param in rbm.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for i in range(10):\n",
    "            initialize = torch.from_numpy(np.random.binomial(1, 0.5, (1000, (l+1-2)*2))).float()\n",
    "            rbm.k = 800\n",
    "            samples = rbm(initialize)[2].detach().numpy()\n",
    "            all_samples.append(samples)\n",
    "        samples = np.concatenate(all_samples)\n",
    "        np.save(savepath+f'repr_results[model={run}]/{run}_samples.npy', samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63cbfd",
   "metadata": {},
   "source": [
    "### linear chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e052d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainLengths = [8, 32]\n",
    "networkSizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500]\n",
    "parent = os.getcwd()\n",
    "savepath = ###directory to save training results in###\n",
    "fname_8 = ###file path of N=8 simulation data###\n",
    "fname_32 = ###file path of N=32 simulation data###\n",
    "fnames = [fname_8, fname_32]\n",
    "\n",
    "for ind, l in enumerate(chainLengths):\n",
    "    fname = fnames[ind]\n",
    "    dataset = polyRBM.CubicChainDataset(fname, 2)\n",
    "    div = int(0.7*len(dataset.data))\n",
    "    testset = dataset.bits[div:]\n",
    "    dataset.data = torch.from_numpy(dataset.bits[:div]).float()\n",
    "    \n",
    "    for n in tqdm(networkSizes):\n",
    "        run = f'rw_exclVol_N{l}_h{int(n)}' #unique identifier is automatically created\n",
    "        os.mkdir(parent+'/'+savepath+f'repr_results[model={run}]')\n",
    "        batchsize = 10\n",
    "        n_vis = 2*(l-2)\n",
    "        n_hidden = int(n)\n",
    "        k = 2\n",
    "        rbm_lr = 10**-2\n",
    "        rbm_epochs= 200\n",
    "        rbm_verbose = False\n",
    "        \n",
    "        train_loader = polyRBM.DataLoader(dataset, batch_size=batchsize, shuffle=True) \n",
    "        rbm = polyRBM.RBM(n_vis=n_vis, n_hin=n_hidden, k=k, oneHot=False, chainlength=l)\n",
    "        \n",
    "        print(f\"START training of RBM [N={l}, n_hidden={int(n)}]\")\n",
    "        print(os.getcwd())\n",
    "        loss, recon_error, countList = polyRBM.train_RBM(rbm=rbm, train_loader=train_loader, epochs=rbm_epochs, \n",
    "                                                 lr=rbm_lr, verbose=rbm_verbose, ninputs=n_vis, \n",
    "                                                 save_model=True, save_path=savepath+f'{run}_rbm', \n",
    "                                                 testset=torch.from_numpy(testset).float(), momentum=0.5, calc_loops=True)\n",
    "        np.save(savepath+f'repr_results[model={run}]/{run}_loss.npy', loss)\n",
    "        np.save(savepath+f'repr_results[model={run}]/{run}_loops.npy', countList)\n",
    "        all_samples = []\n",
    "        \n",
    "        for param in rbm.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for i in tqdm(range(10)):\n",
    "            initialize = torch.from_numpy(np.random.binomial(1, 0.5, (1000, (l-2)*2))).float()\n",
    "            rbm.k = 800\n",
    "            samples = rbm(initialize)[2].detach().numpy()\n",
    "            all_samples.append(samples)\n",
    "        samples = np.concatenate(all_samples)\n",
    "        np.save(savepath+f'repr_results[model={run}]/{run}_samples.npy', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0f3c1",
   "metadata": {},
   "source": [
    "## Quick in-line evaluation of training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e79973",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = ###directory to look for training results and data###\n",
    "run = ###unique identifier of run to be examined###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b096c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and network weights\n",
    "\n",
    "rbm = anaU.loader(savepath, run, rbm=True)\n",
    "loss = anaU.loader(savepath, run, loss=True)\n",
    "anaU.plot_loss(loss, 0)\n",
    "\n",
    "weights = rbm.W.detach().numpy().flatten()\n",
    "v_bias = rbm.v_bias.detach().numpy()\n",
    "h_bias = rbm.h_bias.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].hist(weights, bins=np.linspace(-5, 5, 100), histtype='step', label='W', density=True)\n",
    "ax[0].hist(v_bias, bins=np.linspace(-5, 5, 100), histtype='step', label='b_vis', density=True)\n",
    "ax[0].hist(h_bias, bins=np.linspace(-5, 5, 100), histtype='step', label='b_hid', density=True)\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loop count from training\n",
    "\n",
    "countList = anaU.loader(savepath, run, loops=True)\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "not_zero_loops = np.logical_not((countList==0).all(axis=0))\n",
    "loops = countList[:, not_zero_loops]\n",
    "\n",
    "for i in range(len(loops[0, :])):\n",
    "    loops[:, i][loops[:, i]==0] = None\n",
    "    ax[0].plot(np.linspace(0, rbm_epochs, rbm_epochs), loops[:, i], label=f'l={np.where(not_zero_loops==True)[0][i]}')\n",
    "ax[0].set_title('non-zero loop counts')\n",
    "ax[1].imshow(countList[:, :32+1], interpolation='nearest', aspect='auto')\n",
    "ax[1].set_title('loop counts per epoch as rows')\n",
    "\n",
    "fig.legend()\n",
    "fig.set_size_inches(10, 6)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reconstructions from a trained RBM\n",
    "\n",
    "rbm = anaU.loader(savepath, run, rbm=True)\n",
    "initialize = torch.from_numpy(np.random.binomial(1, 0.5, (100, (32+1-2)*2))).float() #initialize Gibss-sampling randomly\n",
    "#initialize = torch.from_numpy(testset).float() #initialize Gibbs-sampling from valid conformations\n",
    "rbm.k = 800\n",
    "for param in rbm.parameters():\n",
    "        param.requires_grad = False\n",
    "samples = rbm(initialize)[2].detach().numpy()\n",
    "samplesTF = polyRBM.makeVecs(polyRBM.bitsToBonds2DYu(samples))\n",
    "samples_positions = np.cumsum(samplesTF, axis=1)\n",
    "data = polyRBM.makeVecs(dataset.bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c562db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot angle distribution\n",
    "\n",
    "anaU.plot_angleDistribution(data, samplesTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b0a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot bond vector correlation over distance\n",
    "\n",
    "anaU.plot_corr(data, samplesTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a98f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot squared radius of gyration\n",
    "\n",
    "rg2_samples = anaU.rgx_calc(samplesTF, len(samplesTF))\n",
    "rg2_data = anaU.rgx_calc(data, 10000)\n",
    "anaU.plot_Rg2(rg2_data, rg2_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cf2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot distribution of squared end-to-end distance\n",
    "\n",
    "re2_samples = anaU.endToend_calc(samplesTF, 10000)\n",
    "re2_data = anaU.endToend_calc(data, 10000)\n",
    "mean_data = np.mean(re2_data)\n",
    "mean_samples = np.mean(re2_samples)\n",
    "print(mean_data, mean_samples, mean_samples/mean_data)\n",
    "anaU.plot_Re2(re2_data, re2_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
